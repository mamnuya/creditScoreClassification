# -*- coding: utf-8 -*-
"""creditScoreClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KSn1mh6z1TJX8oQNuIXl1F_DwD_48kU_
"""

#Importing the Pandas and Numpy libraries for dealing with dataframes and its manipulations.

import pandas as pd
import numpy as np

df = pd.read_csv("CreditScoreData.csv")
df.head()
df.info()

#Checking the shape of the dataframe
df.shape

df.isnull().sum()

df.columns

#Checking the datatypes for data processing
df.dtypes

df.describe()

#Helps us to gain insights about the type of column and most repeated values for each column
for i in df.columns:
  print("Column name:", i)
  print(df[i].value_counts(dropna=False))
  print("----------------------------------------")

"""Got few insights here that some columns are present with unnecessary characters like "_" and "-" in them."""

#Labeling the categorical data with numbers to enhance statistical processing.
month_dictionary = {"January" : 1,"February" : 2,"March" : 3,"April" : 4,"May" : 5,"June" : 6,"July" : 7,"August" : 8}
df["Month"] = df["Month"].map(month_dictionary)

df.describe()

payment_behavior_dict = {
    'High_spent_Small_value_payments' : 0,
    'Low_spent_Large_value_payments' : 1,
    'Low_spent_Medium_value_payments' : 2,
    'Low_spent_Small_value_payments' : 3,
    'High_spent_Medium_value_payments' : 4,
    'High_spent_Large_value_payments': 5,
    '!@9#%8' : pd.NA
}

df['Payment_Behaviour'] = df['Payment_Behaviour'].map(payment_behavior_dict)

#Finding the columns in which "_" are present to replace it with "" character.
columns_with_underscore = [col for col in df.columns if any("_" in str(value) for value in df[col])]
columns_with_underscore

#Found out this character when previously doing value_counts() method
df['Occupation'] = df['Occupation'].replace("_______", pd.NA)

#From now we are going to find missing values of specific group by associating 'Customer_ID' as a reference to groupby()
df['Occupation'].astype(str)
df['Occupation'] = df.groupby('Customer_ID')['Occupation'].transform(lambda x: x.mode()[0])

#Removing the Underscore charaters from the specified column group.
underscore_columns = ['Age',
 'Annual_Income',
 'Num_of_Loan',
 'Num_of_Delayed_Payment',
 'Changed_Credit_Limit',
 'Outstanding_Debt',
 'Amount_invested_monthly',
 'Monthly_Balance']

def remove_underscore(col):
    df[col] = df[col].apply(lambda x: str(x).replace("_", "") if str(x) else x)
    df[col] = pd.to_numeric(df[col], errors="coerce")

for i in underscore_columns:
  remove_underscore(i)

columns_with_minus = [col for col in df.columns if any("-" in str(value) for value in df[col])]
columns_with_minus

#We are selecting only few columns containing minus as further it would help us in further processing or the minus has a significance
minus_columns = ['Age',
 'Num_Bank_Accounts',
 'Num_of_Loan']
 #'Delay_from_due_date',
 #'Num_of_Delayed_Payment',
 #'Changed_Credit_Limit',
 #'Monthly_Balance'

#Replacing missing values with the most frequent value.
for column in minus_columns:
  df[column] = df[column].astype(str)
  df[column] = df[column].str.replace(r'[^0-9]', '', regex=True)
  df[column] = df[column].replace('', pd.NA)
  df[column] = df.groupby('Customer_ID')[column].transform(lambda x: x.mode()[0])
  df[column] = df[column].astype(int)

#Handling various columns according to their dtypes, mostly objects here.
df["Monthly_Inhand_Salary"] = df.groupby('Customer_ID')["Monthly_Inhand_Salary"].transform(lambda x: x.mode()[0])

df['Credit_Mix'] = df['Credit_Mix'].replace("_", pd.NA)
df["Credit_Mix"] = df.groupby('Customer_ID')["Credit_Mix"].transform(lambda x: x.mode()[0])

df["Payment_Behaviour"] = df.groupby('Customer_ID')["Payment_Behaviour"].transform(lambda x: x.fillna(x.mode()[0]))

df["Num_Credit_Card"] = df.groupby('Customer_ID')["Num_Credit_Card"].transform(lambda x: x.mode()[0])

df["Num_Credit_Inquiries"] = df.groupby('Customer_ID')["Num_Credit_Inquiries"].transform(lambda x: x.mode()[0])

df["Interest_Rate"] = df.groupby('Customer_ID')["Interest_Rate"].transform(lambda x: x.mode()[0])

df["Annual_Income"] = df.groupby('Customer_ID')["Annual_Income"].transform(lambda x: x.mode()[0])

df['Payment_of_Min_Amount'] = df['Payment_of_Min_Amount'].replace('NM', pd.NA)
df['Payment_of_Min_Amount'] = df.groupby('Customer_ID')['Payment_of_Min_Amount'].transform(lambda x: x.mode()[0])

#Here we have some int dtpyes which are filled with the mean of the specific associated group which is 'Customer_ID'

df["Changed_Credit_Limit"] = df.groupby('Customer_ID')["Changed_Credit_Limit"].transform(lambda x: x.fillna(x.mean()))

df["Amount_invested_monthly"] = df.groupby('Customer_ID')["Amount_invested_monthly"].transform(lambda x: x.fillna(x.mean()))

df["Monthly_Balance"] = df.groupby('Customer_ID')["Monthly_Balance"].transform(lambda x: x.fillna(x.mean()))

#Converting the object data of credit age into int dtype y using regular expressions.
import re

def duration_to_months(duration):
    if pd.isnull(duration):
        return None

    m = re.match(r'(\d+) Years? and (\d+) Months?', duration)

    if m:
      years = int(m.group(1))
      months = int(m.group(2))
      total = ((years * 12) + months)
      return total
    else:
        return None

df['Credit_History_Age'] = df['Credit_History_Age'].apply(duration_to_months)

df['Credit_History_Age'] = df.groupby('Customer_ID')['Credit_History_Age'].transform(lambda x: x.fillna(x.mean()))
df['Credit_History_Age'] = df['Credit_History_Age'].astype(int)

df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].apply(lambda x: None if x < 0 else x)
df['Num_of_Delayed_Payment'] = df.groupby('Customer_ID')['Num_of_Delayed_Payment'].transform(lambda x: x.fillna(x.mean()))

# Before label encoder, print some of the data to observe the difference before encoding
df.head(8)

#Using Label encoding to convert into unique numerical identifiers.
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

df["Occupation"] = label_encoder.fit_transform(df["Occupation"])
df["Credit_Mix"] = label_encoder.fit_transform(df["Credit_Mix"])
df["Payment_of_Min_Amount"] = label_encoder.fit_transform(df["Payment_of_Min_Amount"])
df["Credit_Score"]=df["Credit_Score"].map({"Standard":0,"Good":1,"Poor":2})

#Dropping the columns which we have used for group associations and the ones which have no importance.
df.drop("ID", axis=1, inplace=True)
df.drop("Name", axis=1, inplace=True)
df.drop("SSN", axis=1, inplace=True)
df.drop("Type_of_Loan", axis=1, inplace=True)
df.drop("Customer_ID", axis=1, inplace=True)

from sklearn.neighbors import NearestNeighbors
import numpy as np
import matplotlib.pyplot as plt

k = 5

# Selecting only the numerical columns
numerical_columns = df.select_dtypes(include=np.number)

#fit the model
nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto').fit(numerical_columns)

# Computing distances
distances, indices = nbrs.kneighbors(numerical_columns)
k_distance = distances[:, -1]

# Sort in descending order
sorted_distances = np.sort(k_distance)[::-1]

# Plotting the  distances
plt.figure(figsize=(8, 6))
plt.plot(sorted_distances, marker='o', linestyle='-')
plt.xlabel('Data Points')
plt.ylabel(f'{k}-Distance')
plt.title(f'Sorted {k}-Distances of Data Points')
plt.grid(True)
plt.show()
#setting threshold based on the plot
threshold_distance = 1000
plt.axhline(y=threshold_distance, color='r', linestyle='--', label=f'Threshold: {threshold_distance}')
plt.legend()

plt.show()

# Identify outliers
outliers_indices = np.where(k_distance > threshold_distance)[0]
outliers = df.iloc[outliers_indices]

print("Outliers:")
print(outliers)

# Remove outliers from the DataFrame
df_flt = df.drop(outliers_indices)

# Feature Engineering: Add new features

# Calculate the total number of accounts (Bank Accounts + Credit Cards)
df['Total_Num_Accounts'] = df['Num_Bank_Accounts'] + df['Num_Credit_Card']
df_flt['Total_Num_Accounts'] = df_flt['Num_Bank_Accounts'] + df_flt['Num_Credit_Card']
# Calculate the total outstanding debt per account
df['Debt_Per_Account'] = df['Outstanding_Debt'] / df['Total_Num_Accounts']
df_flt['Debt_Per_Account'] = df_flt['Outstanding_Debt'] / df_flt['Total_Num_Accounts']

# Calculate the ratio of outstanding debt to annual income
df['Debt_to_Income_Ratio'] = df['Outstanding_Debt'] / df['Annual_Income']
df_flt['Debt_to_Income_Ratio'] = df_flt['Outstanding_Debt'] / df_flt['Annual_Income']

df.head(3)
df_flt.head(3)

# Check how many columns have 0,1,2 as credit scores to understand the balancing/distribution
# We will likely use SMOTE for oversampling since we do not have perfectly balanced data

print((df["Credit_Score"]==0).sum())
print((df["Credit_Score"]==1).sum())
print((df["Credit_Score"]==2).sum())

print((df_flt["Credit_Score"]==0).sum())
print((df_flt["Credit_Score"]==1).sum())
print((df_flt["Credit_Score"]==2).sum())

# DO FEATURE SELECTION HERE to help the models run smoothly
# Currently: using mutual_info_regression for selecting K best features
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_regression

df.info() # originally there are 26 columns

X = df.drop('Credit_Score', axis=1) # X_train is everything except Credit_Score
y = df['Credit_Score']
#dataframe without outliers
X_flt = df_flt.drop('Credit_Score', axis=1) # X_train is everything except Credit_Score
y_flt= df_flt['Credit_Score']

# We will select the top 14 columns of X
selector = SelectKBest(score_func=mutual_info_regression, k=14)
X_selected = selector.fit_transform(X, y)
#selecting the top features for data withour outliers
selector_flt= SelectKBest(score_func=mutual_info_regression, k=14)
X_selected_flt = selector_flt.fit_transform(X_flt, y_flt)

# Get the indices of the selected columns
selected_indices = selector.get_support(indices=True)
selected_indices_flt = selector_flt.get_support(indices=True)
# Create a DataFrame with the selected columns
X = pd.DataFrame(X_selected, columns=X.columns[selected_indices])
X_flt = pd.DataFrame(X_selected_flt, columns=X_flt.columns[selected_indices_flt])

# Print the most important columns
X.info()
X_flt.info()

# Split the data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=100)

from sklearn.model_selection import train_test_split
X_train_flt, X_test_flt, y_train_flt, y_test_flt = train_test_split(X_flt, y_flt, test_size=0.33, random_state=100)

"""Our dataset has at most 26 columns after feature engineering, and 14 columns after feature selection. Our models performed worse using PCA, thus we did not include PCA as we already had limited amounts of columns.

For example, for RandomForestClassifier we received the following difference with and without PCA


For Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 100}
Accuracy on SMOTE WITH PCA: 0.7020884694947434

and

For Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 100}
Accuracy on SMOTE WITHOUT PCA: 0.7593584403071779

We conclude that PCA decreases the performance so we removed PCA.

"""

# Implement RandomForestClassifier
# Hypertune parameters
# PCA decreased accuracy and performance, so we did not include PCA

# RF WITHOUT PCA
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Define the SMOTE parameters
smote_params = {
    'sampling_strategy': 'auto',
    'random_state': 100,
    'k_neighbors': 5
}

# Create SMOTE instance
smote = SMOTE(**smote_params)
smote_flt = SMOTE(**smote_params)

# Resample the data
X_smote, y_smote = smote.fit_resample(X_train, y_train)
X_smote_flt, y_smote_flt = smote_flt.fit_resample(X_train_flt, y_train_flt)

# Split the data
X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, test_size=0.33, random_state=100)
X_train_smote_flt, X_test_smote_flt, y_train_smote_flt, y_test_smote_flt = train_test_split(X_smote_flt, y_smote_flt, test_size=0.33, random_state=100)

# Create the RandomForestClassifier instance
rf_classifier = RandomForestClassifier(n_estimators=100, bootstrap=True, random_state=100)
rf_classifier_flt = RandomForestClassifier(n_estimators=100, bootstrap=True, random_state=100)

# Define the parameters grid to search

    #Searched through to find the best parameter
    #'n_estimators': [100, 200],
    #'max_depth': [10, 30, 50],
    #'min_samples_leaf': [1, 3, 5]


param_grid = {

    'n_estimators': [100, 200],
    'max_depth': [10, 30, 50],
    'min_samples_leaf': [1, 3, 5]
}

# Create GridSearchCV instance
grid_search = GridSearchCV(rf_classifier, param_grid, cv=3, scoring='accuracy')
grid_search_flt = GridSearchCV(rf_classifier_flt, param_grid, cv=3, scoring='accuracy')

# Fit the GridSearchCV
grid_search.fit(X_train_smote, y_train_smote)
grid_search_flt.fit(X_train_smote_flt, y_train_smote_flt)

# Get the best parameters
best_params = grid_search.best_params_
best_params_flt = grid_search_flt.best_params_

# Get the best estimator
best_rf_classifier = grid_search.best_estimator_
best_rf_classifier_flt = grid_search_flt.best_estimator_

# Predict on test data
y_pred_smote = best_rf_classifier.predict(X_test_smote)
y_pred_smote_flt= best_rf_classifier_flt.predict(X_test_smote_flt)

# Calculate accuracy
accuracy_smote_rf = accuracy_score(y_test_smote, y_pred_smote)
accuracy_smote_rf_flt = accuracy_score(y_test_smote_flt, y_pred_smote_flt)

print("Best Parameters:", best_params)
print("Accuracy on SMOTE:", accuracy_smote_rf)

print("Best Parameters:", best_params_flt)
print("Accuracy on SMOTE:", accuracy_smote_rf_flt)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Evaluate the Random Forest Classifier using the best classifier
y_pred = best_rf_classifier.predict(X_test)
y_pred_flt = best_rf_classifier_flt.predict(X_test_flt)


# Calculate accuracy on the original test set without SMOTE
accuracy_rf = accuracy_score(y_test, y_pred)
print("RF Accuracy on original test set WITHOUT SMOTE:", accuracy_rf)
accuracy_rf_flt = accuracy_score(y_test_flt, y_pred_flt)
print("RF Accuracy on filtered test set WITHOUT SMOTE:", accuracy_rf_flt)

# Print classification report without SMOTE
print('\nRF Classification score WITHOUT SMOTE:\n', classification_report(y_test, y_pred))
print('\nRF Classification score on filtered data WITHOUT SMOTE:\n', classification_report(y_test_flt, y_pred_flt))


# Calculate confusion matrix without SMOTE
cm = confusion_matrix(y_test, y_pred)
cm_flt = confusion_matrix(y_test_flt, y_pred_flt)
# Create a heatmap for the confusion matrix without SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('RF Confusion Matrix without SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_flt, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('RF Confusion Matrix without SMOTE')
plt.show()

# Print accuracy and classification report with SMOTE
print("RF Accuracy on SMOTE:", accuracy_smote_rf)
print('\nRF Classification scores for SMOTE:\n', classification_report(y_test_smote, y_pred_smote))
print("RF Accuracy on filetered data SMOTE:", accuracy_smote_rf_flt)
print('\nRF Classification scores for  filetered data and SMOTE:\n', classification_report(y_test_smote_flt, y_pred_smote_flt))

# Calculate confusion matrix with SMOTE
cm_smote = confusion_matrix(y_test_smote, y_pred_smote)
cm_smote_flt = confusion_matrix(y_test_smote_flt, y_pred_smote_flt)
# Create a heatmap for the confusion matrix with SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('RF Confusion Matrix with SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote_flt, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('RF Confusion Matrix with SMOTE')
plt.show()

"""**To decrease the runtime for randomForestClassifier, the best parameters and printed statements are:**

**BEFORE REMOVING OUTLIERS**

Best Parameters: {'max_depth': 50, 'min_samples_leaf': 3, 'n_estimators': 200}

Accuracy on SMOTE: 0.8563291677293208

Accuracy on original test set WITHOUT SMOTE: 0.7956060606060606

**After Removing Outliers**

Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'n_estimators': 100}

Accuracy on SMOTE: 0.8707188223422567

Accuracy on original test set WITHOUT SMOTE: 0.7983998482069445
"""

# Implement Gaussian Naive Bayes Classifier
# Hypertune parameters

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

# Define the SMOTE parameters
smote_params = {
    'sampling_strategy': 'auto',
    'random_state': 100,
    'k_neighbors': 5
}

# Create SMOTE instance
smote = SMOTE(**smote_params)
smote_flt = SMOTE(**smote_params)

# Resample the data
X_smote, y_smote = smote.fit_resample(X_train, y_train)
X_smote_flt, y_smote_flt = smote_flt.fit_resample(X_train_flt, y_train_flt)

# Split the data
X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, test_size=0.33, random_state=100)
X_train_smote_flt, X_test_smote_flt, y_train_smote_flt, y_test_smote_flt= train_test_split(X_smote_flt, y_smote_flt, test_size=0.33, random_state=100)


# Create the Gaussian Naive Bayes classifier instance
gnb = GaussianNB()
gnb_flt= GaussianNB()


# Define the parameters grid to search


#Searched through to find the best parameter
    #'var_smoothing': [1e-9, 1e-7, 1e-5]

param_grid = {
    'var_smoothing': [1e-9, 1e-7, 1e-5]
}

# Create GridSearchCV instance
grid_search = GridSearchCV(gnb, param_grid, cv=3, scoring='accuracy')
grid_search_flt = GridSearchCV(gnb_flt, param_grid, cv=3, scoring='accuracy')

# Fit the GridSearchCV
grid_search.fit(X_train_smote, y_train_smote)
grid_search_flt.fit(X_train_smote_flt, y_train_smote_flt)
# Get the best parameters
best_params = grid_search.best_params_
best_params_flt = grid_search_flt.best_params_

# Get the best estimator
best_gnb = grid_search.best_estimator_
best_gnb_flt = grid_search_flt.best_estimator_

# Predict on test data
y_pred_smote = best_gnb.predict(X_test_smote)
y_pred_smote_flt = best_gnb_flt.predict(X_test_smote_flt)

# Calculate accuracy
accuracy_smote_nb = accuracy_score(y_test_smote, y_pred_smote)
accuracy_smote_nb_flt = accuracy_score(y_test_smote_flt, y_pred_smote_flt)

print("Best Parameters:", best_params)
print("Accuracy on SMOTE with Gaussian Naive Bayes:", accuracy_smote_nb)

print("Best Parameters:", best_params_flt)
print("Accuracy on filetered data and SMOTE with Gaussian Naive Bayes:", accuracy_smote_nb_flt)

"""**To decrease the runtime for Gaussian Naive Bayes, the best parameters and printed lines are:**

BEFORE REMOVING OUTLIERS

Best Parameters: {'var_smoothing': 1e-09}
Accuracy on SMOTE with Gaussian Naive Bayes: 0.6607441412338122

Accuracy on original test set WITHOUT SMOTE: 0.5805757575757575


**After removing outliers**

Best Parameters: {'var_smoothing': 1e-09}

GNB Accuracy on filetered and SMOTE: 0.6505609307295067

Accuracy on filtered test set WITHOUT SMOTE :0.5413003605085067
"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Evaluate the Gaussian Naive Bayes Classifier using the best classifier
y_pred = best_gnb.predict(X_test)
y_pred_flt= best_gnb_flt.predict(X_test_flt)

# Calculate accuracy on the original test set without SMOTE
accuracy_nb = accuracy_score(y_test, y_pred)
print("GNB Accuracy on original test set WITHOUT SMOTE:", accuracy_nb)
accuracy_nb_flt = accuracy_score(y_test_flt, y_pred_flt)
print("GNB Accuracy on Filtered test set WITHOUT SMOTE:", accuracy_nb_flt)

# Print classification report without SMOTE
print('\nGNB Classification score WITHOUT SMOTE:\n', classification_report(y_test, y_pred))
print('\nGNB Classification score on filtered data WITHOUT SMOTE:\n', classification_report(y_test_flt, y_pred_flt))

# Calculate confusion matrix without SMOTE
cm = confusion_matrix(y_test, y_pred)
cm_flt = confusion_matrix(y_test_flt, y_pred_flt)

# Create a heatmap for the confusion matrix without SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('GNB Confusion Matrix without SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_flt, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('GNB Confusion Matrix without SMOTE')
plt.show()

# Print accuracy and classification report with SMOTE
print("GNB Accuracy on SMOTE:", accuracy_smote_nb)
print('\nGNB Classification scores for SMOTE:\n', classification_report(y_test_smote, y_pred_smote))
print("GNB Accuracy on filetered and SMOTE:", accuracy_smote_nb_flt)
print('\nGNB Classification scores for filtered and SMOTE:\n', classification_report(y_test_smote_flt, y_pred_smote_flt))

# Calculate confusion matrix with SMOTE
cm_smote = confusion_matrix(y_test_smote, y_pred_smote)
cm_smote_flt = confusion_matrix(y_test_smote_flt, y_pred_smote_flt)

# Create a heatmap for the confusion matrix with SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('GNB Confusion Matrix with SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote_flt, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('GNB Confusion Matrix with filtered SMOTE')
plt.show()

#Implement KNN

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Define the SMOTE parameters
smote_params = {
    'sampling_strategy': 'auto',
    'random_state': 100,
    'k_neighbors': 5
}

# Create SMOTE instance
smote = SMOTE(**smote_params)
smote_flt = SMOTE(**smote_params)

# Resample the data
X_smote, y_smote = smote.fit_resample(X_train, y_train)
X_smote_flt, y_smote_flt = smote_flt.fit_resample(X_train_flt, y_train_flt)

# Split the data
X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, test_size=0.33, random_state=100)
X_train_smote_flt, X_test_smote_flt, y_train_smote_flt, y_test_smote_flt = train_test_split(X_smote_flt, y_smote_flt, test_size=0.33, random_state=100)

# Create the KNN classifier instance
knn = KNeighborsClassifier()
knn_flt = KNeighborsClassifier()

#Searched through to find the best parameter
    #'n_neighbors': [5, 15, 25, 50],  # number of neighbors
    #'weights': ['uniform', 'distance'],  # weight function
    #'metric': ['euclidean', 'manhattan']  # distance metric

# Define the parameters grid to search
param_grid = {
    'n_neighbors': [5, 15, 25, 50],  # number of neighbors
    'weights': ['uniform', 'distance'],  # weight function
    'metric': ['euclidean', 'manhattan']  # distance metric
}

# Create GridSearchCV instance
grid_search = GridSearchCV(knn, param_grid, cv=3, scoring='accuracy')
grid_search_flt = GridSearchCV(knn_flt, param_grid, cv=3, scoring='accuracy')

# Fit the GridSearchCV
grid_search.fit(X_train_smote, y_train_smote)
grid_search_flt.fit(X_train_smote_flt, y_train_smote_flt)

# Get the best parameters
best_params = grid_search.best_params_
best_params_flt= grid_search_flt.best_params_
# Get the best estimator
best_knn = grid_search.best_estimator_
best_knn_flt = grid_search_flt.best_estimator_

# Predict on test data
y_pred_smote = best_knn.predict(X_test_smote)
y_pred_smote_flt = best_knn_flt.predict(X_test_smote_flt)

# Calculate accuracy
accuracy_smote_knn = accuracy_score(y_test_smote, y_pred_smote)
accuracy_smote_knn_flt = accuracy_score(y_test_smote_flt, y_pred_smote_flt)

print("Best Parameters:", best_params)
print("Accuracy on SMOTE with KNN:", accuracy_smote_knn)
print("Best Parameters:", best_params_flt)
print("Accuracy on SMOTE with KNN:", accuracy_smote_knn_flt)

"""**To decrease the runtime for KNN, the best parameters and printed lines are:**

**BEFORE REMOVING OUTLIERS**

Best Parameters: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}
Accuracy on SMOTE with KNN: 0.8593896114936665

Accuracy on original test set WITHOUT SMOTE: 0.7851212121212121

Accuracy on SMOTE with KNN CLASSIFIER: 0.8593896114936665

**After Oulier Removal**

Best Parameters: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}
Accuracy on SMOTE with KNN: 0.8679883658811658

KNN Accuracy on Filtered test set WITHOUT SMOTE: 0.7954904813104801

KNN Accuracy on Filetered with SMOTE: 0.8679883658811658
"""

# Evaluate the KNN Classifier using the best classifier
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

y_pred = best_knn.predict(X_test)
y_pred_flt= best_knn_flt.predict(X_test_flt)

# Calculate accuracy on the original test set without SMOTE
accuracy_knn = accuracy_score(y_test, y_pred)
print("KNN Accuracy on original test set WITHOUT SMOTE:", accuracy_knn)

# Print classification report without SMOTE
print('\nKNN Classification score WITHOUT SMOTE:\n', classification_report(y_test, y_pred))
accuracy_knn_flt = accuracy_score(y_test_flt, y_pred_flt)
print("KNN Accuracy on Filtered test set WITHOUT SMOTE:", accuracy_knn_flt)

# Print classification report without SMOTE
print('\nKNN Classification score on Filtered data WITHOUT SMOTE:\n', classification_report(y_test_flt, y_pred_flt))

# Calculate confusion matrix without SMOTE
cm = confusion_matrix(y_test, y_pred)
cm_flt = confusion_matrix(y_test_flt, y_pred_flt)

# Create a heatmap for the confusion matrix without SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('KNN Confusion Matrix without SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_flt, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('KNN Confusion Matrix without SMOTE')
plt.show()

# Print accuracy and classification report with SMOTE
print("KNN Accuracy on SMOTE:", accuracy_smote_knn)
print('\nKNN Classification scores for SMOTE:\n', classification_report(y_test_smote, y_pred_smote))
print("KNN Accuracy on Filetered with SMOTE:", accuracy_smote_knn_flt)
print('\nKNN Classification scores for  Filtered data with SMOTE:\n', classification_report(y_test_smote_flt, y_pred_smote_flt))

# Calculate confusion matrix with SMOTE
cm_smote = confusion_matrix(y_test_smote, y_pred_smote)
cm_smote_flt = confusion_matrix(y_test_smote_flt, y_pred_smote_flt)

# Create a heatmap for the confusion matrix with SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('KNN Confusion Matrix with SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote_flt, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('KNN Confusion Matrix with SMOTE')
plt.show()

# Implement XGBoost
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, GridSearchCV
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Define the SMOTE parameters
smote_params = {
    'sampling_strategy': 'auto',
    'random_state': 100,
    'k_neighbors': 5
}

# Create SMOTE instance
smote = SMOTE(**smote_params)
smote_flt = SMOTE(**smote_params)

# Resample the data
X_smote, y_smote = smote.fit_resample(X_train, y_train)
X_smote_flt, y_smote_flt = smote_flt.fit_resample(X_train_flt, y_train_flt)

# Split the data
X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, test_size=0.33, random_state=100)
X_train_smote_flt, X_test_smote_flt, y_train_smote_flt, y_test_smote_flt = train_test_split(X_smote_flt, y_smote_flt, test_size=0.33, random_state=100)

# Create the XGBoost classifier instance
xgb_classifier = XGBClassifier()
xgb_classifier_flt = XGBClassifier()

# Define the parameters grid to search
#Searched through to find the best parameter
    #'n_estimators': [100, 200],
    #'max_depth': [10, 30, 50],
    #'min_child_weight': [1, 3, 5]

    # The best parameters found from this code BEFORE REMOVING OUTLIERS are:
    #'n_estimators': [200],
    #'max_depth': [10],
    #'min_child_weight': [5]

# {'max_depth': 10, 'min_child_weight': 5, 'n_estimators': 200}
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 30, 50],
    'min_child_weight': [1, 3, 5]
}

# Create GridSearchCV instance
grid_search = GridSearchCV(xgb_classifier, param_grid, cv=3, scoring='accuracy')
grid_search_flt = GridSearchCV(xgb_classifier_flt, param_grid, cv=3, scoring='accuracy')

# Fit the GridSearchCV
grid_search.fit(X_train_smote, y_train_smote)
grid_search_flt.fit(X_train_smote_flt, y_train_smote_flt)

# Get the best parameters
best_params = grid_search.best_params_
best_params_flt= grid_search_flt.best_params_

# Get the best estimator
best_xgb_classifier = grid_search.best_estimator_
best_xgb_classifier_flt= grid_search_flt.best_estimator_

# Predict on test data
y_pred_smote = best_xgb_classifier.predict(X_test_smote)
y_pred_smote_flt = best_xgb_classifier_flt.predict(X_test_smote_flt)

# Calculate accuracy
accuracy_smote_xgb = accuracy_score(y_test_smote, y_pred_smote)
accuracy_smote_xgb_flt = accuracy_score(y_test_smote_flt, y_pred_smote_flt)

print("Best Parameters:", best_params)
print("Accuracy on SMOTE with XGBoost:", accuracy_smote_xgb)
print("Best Parameters:", best_params_flt)
print("Accuracy on SMOTE with XGBoost:", accuracy_smote_xgb_flt)

"""**To decrease the runtime for XGBOOST, the best parameters and printed lines are:**

**BEFORE REMOVING OUTLIERS**

Best Parameters: {'max_depth': 10, 'min_child_weight': 5, 'n_estimators': 200}
Accuracy on SMOTE with XGBoost: 0.8708946130522259

Accuracy on original test set WITHOUT SMOTE: 0.7994242424242424

Accuracy on SMOTE with KNN CLASSIFIER: 0.8708946130522259

**After outlier removal**

Best Parameters: {'max_depth': 10, 'min_child_weight': 3, 'n_estimators': 200}
Accuracy on SMOTE with XGBoost: 0.8734492788033478

XGB Accuracy on Filtered test set WITHOUT SMOTE: 0.7964708114603757

XGB Accuracy on Filtered  with SMOTE: 0.8734492788033478

"""

# Evaluate the XGBoost Classifier using the best classifier
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

y_pred = best_xgb_classifier.predict(X_test)
y_pred_flt = best_xgb_classifier_flt.predict(X_test_flt)

# Calculate accuracy on the original test set without SMOTE
accuracy_xgb = accuracy_score(y_test, y_pred)
print("XGB Accuracy on original test set WITHOUT SMOTE:", accuracy_xgb)

# Print classification report without SMOTE
print('\nXGB Classification score WITHOUT SMOTE:\n', classification_report(y_test, y_pred))

accuracy_xgb_flt = accuracy_score(y_test_flt, y_pred_flt)
print("XGB Accuracy on Filtered test set WITHOUT SMOTE:", accuracy_xgb_flt)

# Print classification report without SMOTE
print('\nXGB Classification score on Filtered data WITHOUT SMOTE:\n', classification_report(y_test_flt, y_pred_flt))

# Calculate confusion matrix without SMOTE
cm = confusion_matrix(y_test, y_pred)
cm_flt = confusion_matrix(y_test_flt, y_pred_flt)

# Create a heatmap for the confusion matrix without SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('XGB Confusion Matrix without SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_flt, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('XGB Confusion Matrix without SMOTE')
plt.show()

# Print accuracy and classification report with SMOTE
print("XGB Accuracy on SMOTE:", accuracy_smote_xgb)
print('\nXGB Classification scores for SMOTE:\n', classification_report(y_test_smote, y_pred_smote))
# Print accuracy and classification report with SMOTE
print("XGB Accuracy on Filtered  with SMOTE:", accuracy_smote_xgb_flt)
print('\nXGB Classification scores for Filtered data with SMOTE:\n', classification_report(y_test_smote_flt, y_pred_smote_flt))

# Calculate confusion matrix with SMOTE
cm_smote = confusion_matrix(y_test_smote, y_pred_smote)
cm_smote_flt = confusion_matrix(y_test_smote_flt, y_pred_smote_flt)

# Create a heatmap for the confusion matrix with SMOTE
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('XGB Confusion Matrix with SMOTE')
plt.show()
plt.figure(figsize=(8, 6))
sns.heatmap(cm_smote_flt, annot=True, fmt='d', cmap='Greens', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('XGB Confusion Matrix with SMOTE')
plt.show()

"""**Summary thus far:**
We did data pre-processing and added new features for feature engineering. Note to interpret the confusion matrices: {"Standard": class 0,"Good": class 1,"Poor": class 2}

We found that the top 14 columns most important for credit score classification based on mutual information score were:
*   Annual_Income
*   Monthly_Inhand_Salary
*   Num_Credit_Card
*   Interest_Rate
*   Delay_from_due_date
* Num_Credit_Inquiries
* Credit_Mix  
* Outstanding_Debt
* Credit_History_Age
* Payment_of_Min_Amount
* Total_EMI_per_month
* Total_Num_Accounts
* Debt_Per_Account
* Debt_to_Income_Ratio

The columns least important for credit score classification based on mutual information score were:
* Month
* Age
* Occupation
* Num_Bank_Accounts
* Num_of_Loan                
* Num_of_Delayed_Payment    
* Changed_Credit_Limit     
* Credit_Utilization_Ratio  
* Amount_invested_monthly   
* Payment_Behaviour           
* Monthly_Balance           



Based on the classification reports, we decided to the best model to classify credit scores was using the hypertuned **XGBoost**. We chose this model because **this algorithm has the ability to handle high-dimensional data like ours and captures the complex patterns. It also efficient working with large datasets like ours with 100,000 data points. It sequentially trains the model by assigning weights to each datapoints every round and adjusting their weights depending on whether they have predicted correctly or falsely**.
"""

# Create any visualizations
models = ['Random Forest', 'Naive Bayes','KNN', 'XGBoost']
conditions = [ 'without_SMOTE','without_SMOTE_without_outliers','with_SMOTE', 'with_SMOTE_without_outliers']

without_SMOTE = [accuracy_rf,accuracy_nb ,accuracy_knn,accuracy_xgb]
#without_SMOTE_without_outliers = [accuracy_rf_flt,accuracy_nb_flt, accuracy_knn_flt,accuracy_xgb_flt ]
with_SMOTE = [accuracy_smote_rf,accuracy_smote_nb,accuracy_smote_knn,accuracy_smote_xgb]
with_SMOTE_without_outliers = [accuracy_smote_rf_flt,accuracy_smote_nb_flt,accuracy_smote_knn_flt, accuracy_smote_xgb_flt]


# Create a dictionary to map condition names to accuracy lists
accuracy_dict = {
    'with_SMOTE': with_SMOTE,
    'without_SMOTE_without_outliers': without_SMOTE_without_outliers,
    'without_SMOTE': without_SMOTE,
    'with_SMOTE_without_outliers': with_SMOTE_without_outliers
}

# Plotting the graph
bar_width = 0.15
index = np.arange(len(models))

for i, condition in enumerate(conditions):
    plt.bar(index + i * bar_width, accuracy_dict[condition], bar_width, label=condition.replace('_', ' '))

plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Model Accuracies with Different Conditions')
plt.xticks(index + bar_width * (len(conditions) - 1) / 2, models)
plt.gcf().set_size_inches(10, 6)
plt.legend(loc='upper left', bbox_to_anchor=(1.02, 1))
plt.yticks(np.arange(0, 1.05, 0.05))
plt.tight_layout()
plt.show()

from tabulate import tabulate

# Organizing data into rows
data = []
for model in models:
    row = [model]
    for condition in conditions:
        row.append(accuracy_dict[condition][models.index(model)])
    data.append(row)

# Headers
headers = ['Model'] + [condition.replace('_', ' ') for condition in conditions]

# Print table
print(tabulate(data, headers=headers))

import matplotlib.pyplot as plt

# Data for classifiers
accuracy_data = {
    'Random Forest': [accuracy_rf, accuracy_rf_flt, accuracy_smote_rf, accuracy_smote_rf_flt],
    'Naive Bayes': [accuracy_nb, accuracy_nb_flt, accuracy_smote_nb, accuracy_smote_nb_flt],
    'KNN': [accuracy_knn, accuracy_knn_flt, accuracy_smote_knn, accuracy_smote_knn_flt],
    'XGBoost': [accuracy_xgb, accuracy_xgb_flt, accuracy_smote_xgb, accuracy_smote_xgb_flt]
}

# Conditions
conditions = ['Without SMOTE', 'Without SMOTE (No Outliers)', 'With SMOTE', 'With SMOTE (No Outliers)']
bar_width = 0.2
fig, axs = plt.subplots(4, 1, figsize=(10, 20))

# Plotting for each classifier
for i, (classifier, data) in enumerate(accuracy_data.items()):
    index = range(len(data))
    ax = axs[i]
    for j, acc in enumerate(data):
        color = 'C{}'.format(j)  # Using different colors for each condition
        ax.barh(j, acc, bar_width, label=conditions[j], color=color)
        ax.text(acc + 0.01, j, f'{acc*100:.2f}%', color='black', va='center')  # Adding percentage values as text
    ax.set_yticks(index)
    ax.set_yticklabels(conditions)
    ax.set_xlabel('Accuracy')
    ax.set_title(f'Accuracy of {classifier} Classifier with Different Conditions')

plt.tight_layout()
plt.show()